# Discourse
    * Cohesion: interpreation of some element is dependent of that of another
        * referential: anaphora and co-reference
        * lexical: repitition and co-location
    * Coherence: logical and relational connection of different parts of text
    * Consistency: repeated term should keep same translation throughout whole document


# Misc
    * http://computing.dcu.ie/sites/default/files/documents/videos/longyue-wang-transfer-talk-2nd-may-2017/My_Transfer_Longyue_v5.pdf


# Integrating Context Information Techniques
    * Encoder+Attention for each context-sentence on RNN architecture [(April 2017, Jean et al.: Does Neural Machine Translation benefit from Larger Context?)](https://github.com/ducthanhtran/paper_notes/blob/master/machine_learning/nlp/machine_translation/17_does_nmt_benefit_from_larger_context.md)

    * [(September 2017, Tiedemann et al.: Neural Machine Translation with Extended Context)](https://github.com/ducthanhtran/paper_notes/blob/master/machine_learning/nlp/machine_translation/17_nmt_with_extended_context.md)

    * shared Transformer encoder for context-sentence followed by gated sum [(May 2018, Voita et al.: Context-Aware Neural Machine Translation Learns Anaphora Resolution)](https://github.com/ducthanhtran/paper_notes/blob/master/machine_learning/nlp/machine_translation/18_context_aware_nmt_learns_anaphora_resolution.md)
